"""
AI-Powered Vulnerability Analysis Module for BoomSQL
Provides intelligent analysis of SQL injection vulnerabilities using pattern recognition
"""

import json
import time
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum
import re
import statistics
from collections import Counter

from .sql_injection_engine import VulnerabilityResult, DatabaseType
from .logger import LoggerMixin

class VulnerabilityRisk(Enum):
    """Vulnerability risk levels"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"

class AttackVector(Enum):
    """Possible attack vectors"""
    DATA_EXTRACTION = "data_extraction"
    AUTHENTICATION_BYPASS = "authentication_bypass"
    PRIVILEGE_ESCALATION = "privilege_escalation"
    CODE_EXECUTION = "code_execution"
    DENIAL_OF_SERVICE = "denial_of_service"
    FILE_SYSTEM_ACCESS = "file_system_access"

@dataclass
class AIAnalysisResult:
    """AI analysis result for vulnerability"""
    vulnerability_id: str
    risk_score: float  # 0-10 scale
    risk_level: VulnerabilityRisk
    confidence: float  # 0-1 scale
    attack_vectors: List[AttackVector]
    exploitation_complexity: str
    impact_analysis: Dict[str, Any]
    remediation_suggestions: List[str]
    similar_vulnerabilities: List[str]
    threat_intelligence: Dict[str, Any]

@dataclass
class SecurityMetrics:
    """Security metrics for the analyzed application"""
    total_vulnerabilities: int
    critical_count: int
    high_count: int
    medium_count: int
    low_count: int
    security_score: float  # 0-100 scale
    compliance_status: Dict[str, bool]
    trending_analysis: Dict[str, Any]

class AIVulnerabilityAnalyzer(LoggerMixin):
    """AI-powered vulnerability analyzer"""
    
    def __init__(self):
        self.vulnerability_patterns = self._load_vulnerability_patterns()
        self.attack_signatures = self._load_attack_signatures()
        self.threat_intelligence = self._load_threat_intelligence()
        
    def _load_vulnerability_patterns(self) -> Dict[str, Any]:
        """Load vulnerability pattern database"""
        return {
            "sql_injection": {
                "union_based": {
                    "risk_multiplier": 1.2,
                    "attack_vectors": [AttackVector.DATA_EXTRACTION, AttackVector.AUTHENTICATION_BYPASS],
                    "complexity": "medium"
                },
                "error_based": {
                    "risk_multiplier": 1.0,
                    "attack_vectors": [AttackVector.DATA_EXTRACTION],
                    "complexity": "low"
                },
                "blind_based": {
                    "risk_multiplier": 0.8,
                    "attack_vectors": [AttackVector.DATA_EXTRACTION],
                    "complexity": "high"
                },
                "time_based": {
                    "risk_multiplier": 0.9,
                    "attack_vectors": [AttackVector.DATA_EXTRACTION, AttackVector.DENIAL_OF_SERVICE],
                    "complexity": "medium"
                }
            },
            "database_specific": {
                DatabaseType.MYSQL: {
                    "file_access_risk": 1.3,
                    "command_execution": [AttackVector.CODE_EXECUTION, AttackVector.FILE_SYSTEM_ACCESS]
                },
                DatabaseType.MSSQL: {
                    "file_access_risk": 1.5,
                    "command_execution": [AttackVector.CODE_EXECUTION, AttackVector.PRIVILEGE_ESCALATION]
                },
                DatabaseType.POSTGRESQL: {
                    "file_access_risk": 1.2,
                    "command_execution": [AttackVector.CODE_EXECUTION]
                },
                DatabaseType.ORACLE: {
                    "file_access_risk": 1.1,
                    "command_execution": [AttackVector.CODE_EXECUTION, AttackVector.PRIVILEGE_ESCALATION]
                }
            }
        }
    
    def _load_attack_signatures(self) -> Dict[str, Any]:
        """Load attack signature database"""
        return {
            "advanced_techniques": [
                {"name": "Second-Order SQLi", "risk_increase": 0.3},
                {"name": "NoSQL Injection", "risk_increase": 0.2},
                {"name": "XML Injection", "risk_increase": 0.25},
                {"name": "LDAP Injection", "risk_increase": 0.2},
                {"name": "ORM Injection", "risk_increase": 0.15}
            ],
            "evasion_techniques": [
                {"name": "WAF Bypass", "detection_difficulty": 0.4},
                {"name": "Encoding Evasion", "detection_difficulty": 0.3},
                {"name": "Comment Injection", "detection_difficulty": 0.2}
            ]
        }
    
    def _load_threat_intelligence(self) -> Dict[str, Any]:
        """Load threat intelligence data"""
        return {
            "trending_attacks": [
                {"type": "Supply Chain SQLi", "frequency": 0.15, "severity": "high"},
                {"type": "API Injection", "frequency": 0.25, "severity": "medium"},
                {"type": "Cloud Database Injection", "frequency": 0.20, "severity": "high"}
            ],
            "vulnerability_databases": [
                "CVE", "NVD", "OWASP Top 10", "CWE"
            ],
            "exploit_frameworks": [
                "Metasploit", "SQLMap", "Havij", "BBQSQL"
            ]
        }
    
    def analyze_vulnerability(self, vulnerability: VulnerabilityResult) -> AIAnalysisResult:
        """Perform AI-powered analysis of a vulnerability"""
        self.log_info(f"Analyzing vulnerability: {vulnerability.url}")
        
        # Calculate base risk score
        base_risk = self._calculate_base_risk(vulnerability)
        
        # Apply AI enhancements
        enhanced_risk = self._apply_ai_enhancements(vulnerability, base_risk)
        
        # Determine risk level
        risk_level = self._determine_risk_level(enhanced_risk)
        
        # Identify attack vectors
        attack_vectors = self._identify_attack_vectors(vulnerability)
        
        # Calculate confidence
        confidence = self._calculate_confidence(vulnerability)
        
        # Generate impact analysis
        impact_analysis = self._generate_impact_analysis(vulnerability, enhanced_risk)
        
        # Generate remediation suggestions
        remediation = self._generate_remediation_suggestions(vulnerability)
        
        # Find similar vulnerabilities
        similar_vulns = self._find_similar_vulnerabilities(vulnerability)
        
        # Get threat intelligence
        threat_intel = self._get_threat_intelligence(vulnerability)
        
        return AIAnalysisResult(
            vulnerability_id=f"BOOM-{int(time.time())}-{hash(vulnerability.url) % 10000}",
            risk_score=enhanced_risk,
            risk_level=risk_level,
            confidence=confidence,
            attack_vectors=attack_vectors,
            exploitation_complexity=self._assess_complexity(vulnerability),
            impact_analysis=impact_analysis,
            remediation_suggestions=remediation,
            similar_vulnerabilities=similar_vulns,
            threat_intelligence=threat_intel
        )
    
    def _calculate_base_risk(self, vuln: VulnerabilityResult) -> float:
        """Calculate base risk score (0-10)"""
        risk = 5.0  # Base risk
        
        # Adjust based on injection type
        if vuln.injection_type:
            type_name = vuln.injection_type.value.lower()
            if "union" in type_name:
                risk += 2.0
            elif "error" in type_name:
                risk += 1.5
            elif "blind" in type_name:
                risk += 1.0
            elif "time" in type_name:
                risk += 1.2
        
        # Adjust based on database type
        db_risks = {
            DatabaseType.MSSQL: 1.5,
            DatabaseType.MYSQL: 1.3,
            DatabaseType.POSTGRESQL: 1.2,
            DatabaseType.ORACLE: 1.4,
        }
        risk *= db_risks.get(vuln.database_type, 1.0)
        
        # Adjust based on confidence
        risk *= vuln.confidence
        
        return min(risk, 10.0)
    
    def _apply_ai_enhancements(self, vuln: VulnerabilityResult, base_risk: float) -> float:
        """Apply AI-based risk enhancements"""
        enhanced_risk = base_risk
        
        # URL pattern analysis
        if self._has_sensitive_patterns(vuln.url):
            enhanced_risk += 0.5
        
        # Parameter analysis
        if self._has_dangerous_parameters(vuln.parameter):
            enhanced_risk += 0.3
        
        # Payload effectiveness analysis
        if vuln.payload and self._is_advanced_payload(vuln.payload):
            enhanced_risk += 0.4
        
        return min(enhanced_risk, 10.0)
    
    def _has_sensitive_patterns(self, url: str) -> bool:
        """Check if URL contains sensitive patterns"""
        sensitive_patterns = [
            r'/admin/', r'/login/', r'/user/', r'/account/', r'/profile/',
            r'/api/', r'/v\d+/', r'/dashboard/', r'/management/'
        ]
        return any(re.search(pattern, url, re.IGNORECASE) for pattern in sensitive_patterns)
    
    def _has_dangerous_parameters(self, parameter: str) -> bool:
        """Check if parameter name suggests dangerous functionality"""
        dangerous_params = [
            'id', 'user_id', 'admin', 'role', 'auth', 'token',
            'file', 'path', 'cmd', 'exec', 'query', 'search'
        ]
        return any(param.lower() in parameter.lower() for param in dangerous_params)
    
    def _is_advanced_payload(self, payload: str) -> bool:
        """Check if payload uses advanced techniques"""
        advanced_indicators = [
            'UNION', 'SELECT', 'FROM', 'WHERE', 'ORDER BY',
            'BENCHMARK', 'SLEEP', 'WAITFOR', 'DELAY',
            'LOAD_FILE', 'INTO OUTFILE', 'xp_cmdshell'
        ]
        return any(indicator in payload.upper() for indicator in advanced_indicators)
    
    def _determine_risk_level(self, risk_score: float) -> VulnerabilityRisk:
        """Determine risk level based on score"""
        if risk_score >= 8.5:
            return VulnerabilityRisk.CRITICAL
        elif risk_score >= 7.0:
            return VulnerabilityRisk.HIGH
        elif risk_score >= 5.0:
            return VulnerabilityRisk.MEDIUM
        elif risk_score >= 3.0:
            return VulnerabilityRisk.LOW
        else:
            return VulnerabilityRisk.INFO
    
    def _identify_attack_vectors(self, vuln: VulnerabilityResult) -> List[AttackVector]:
        """Identify possible attack vectors"""
        vectors = [AttackVector.DATA_EXTRACTION]  # Always possible with SQLi
        
        # Database-specific vectors
        db_vectors = self.vulnerability_patterns["database_specific"].get(vuln.database_type, {})
        vectors.extend(db_vectors.get("command_execution", []))
        
        # URL-based vectors
        if self._has_sensitive_patterns(vuln.url):
            vectors.append(AttackVector.AUTHENTICATION_BYPASS)
            vectors.append(AttackVector.PRIVILEGE_ESCALATION)
        
        return list(set(vectors))  # Remove duplicates
    
    def _calculate_confidence(self, vuln: VulnerabilityResult) -> float:
        """Calculate analysis confidence"""
        base_confidence = vuln.confidence
        
        # Increase confidence if multiple indicators present
        if vuln.error_message and vuln.payload:
            base_confidence += 0.1
        
        # Increase confidence for well-known database types
        if vuln.database_type in [DatabaseType.MYSQL, DatabaseType.MSSQL]:
            base_confidence += 0.05
        
        return min(base_confidence, 1.0)
    
    def _generate_impact_analysis(self, vuln: VulnerabilityResult, risk_score: float) -> Dict[str, Any]:
        """Generate comprehensive impact analysis"""
        return {
            "data_breach_risk": min(risk_score / 10 * 100, 100),
            "business_impact": self._assess_business_impact(vuln, risk_score),
            "compliance_violations": self._check_compliance_violations(vuln),
            "potential_damage": self._estimate_potential_damage(risk_score),
            "attack_scenarios": self._generate_attack_scenarios(vuln)
        }
    
    def _assess_business_impact(self, vuln: VulnerabilityResult, risk_score: float) -> str:
        """Assess business impact level"""
        if risk_score >= 8.5:
            return "Severe - Complete system compromise possible"
        elif risk_score >= 7.0:
            return "High - Significant data exposure risk"
        elif risk_score >= 5.0:
            return "Medium - Limited data access possible"
        else:
            return "Low - Minimal business impact"
    
    def _check_compliance_violations(self, vuln: VulnerabilityResult) -> List[str]:
        """Check for compliance violations"""
        violations = []
        
        # Always check common compliance frameworks
        violations.extend([
            "OWASP Top 10 - A03 Injection",
            "CWE-89 - SQL Injection"
        ])
        
        # Add specific violations based on URL patterns
        if self._has_sensitive_patterns(vuln.url):
            violations.extend([
                "PCI DSS - Requirement 6.3.1",
                "GDPR - Article 32 Security",
                "SOX - Section 404 Controls"
            ])
        
        return violations
    
    def _estimate_potential_damage(self, risk_score: float) -> Dict[str, str]:
        """Estimate potential damage categories"""
        if risk_score >= 8.5:
            return {
                "financial": "High ($100K+ potential loss)",
                "reputation": "Severe damage",
                "legal": "Regulatory fines likely",
                "operational": "Service disruption"
            }
        elif risk_score >= 7.0:
            return {
                "financial": "Medium ($10K-100K potential loss)",
                "reputation": "Moderate damage",
                "legal": "Possible compliance issues",
                "operational": "Limited disruption"
            }
        else:
            return {
                "financial": "Low (<$10K potential loss)",
                "reputation": "Minimal impact",
                "legal": "No immediate concerns",
                "operational": "No disruption expected"
            }
    
    def _generate_attack_scenarios(self, vuln: VulnerabilityResult) -> List[str]:
        """Generate realistic attack scenarios"""
        scenarios = [
            f"Attacker injects malicious SQL via {vuln.parameter} parameter",
            f"Database {vuln.database_type.value} contents extracted through {vuln.injection_type.value}",
            "Sensitive user data (passwords, emails, PII) compromised"
        ]
        
        if vuln.database_type in [DatabaseType.MSSQL, DatabaseType.MYSQL]:
            scenarios.append("File system access gained through database functions")
            scenarios.append("Operating system commands executed via database")
        
        return scenarios
    
    def _generate_remediation_suggestions(self, vuln: VulnerabilityResult) -> List[str]:
        """Generate specific remediation suggestions"""
        suggestions = [
            "Implement parameterized queries/prepared statements",
            "Add input validation and sanitization",
            "Apply principle of least privilege to database accounts",
            "Enable database logging and monitoring",
            "Regular security testing and code reviews"
        ]
        
        # Database-specific suggestions
        if vuln.database_type == DatabaseType.MSSQL:
            suggestions.extend([
                "Disable xp_cmdshell if not required",
                "Review SQL Server surface area configuration",
                "Implement SQL Server audit features"
            ])
        elif vuln.database_type == DatabaseType.MYSQL:
            suggestions.extend([
                "Disable file_priv if not required",
                "Review MySQL privilege system",
                "Enable MySQL general query log"
            ])
        
        return suggestions
    
    def _find_similar_vulnerabilities(self, vuln: VulnerabilityResult) -> List[str]:
        """Find similar vulnerability patterns"""
        return [
            f"Similar {vuln.injection_type.value} vulnerabilities in same application",
            f"Common {vuln.database_type.value} injection patterns",
            "Parameter-based injection in similar applications",
            "Authentication bypass through SQL injection"
        ]
    
    def _get_threat_intelligence(self, vuln: VulnerabilityResult) -> Dict[str, Any]:
        """Get relevant threat intelligence"""
        return {
            "active_exploits": [
                "Automated scanning tools targeting this vulnerability type",
                "Known exploit frameworks with similar payloads"
            ],
            "threat_actors": [
                "Script kiddies using automated tools",
                "Cybercriminal groups targeting web applications",
                "Advanced persistent threat (APT) groups"
            ],
            "trending_techniques": self.threat_intelligence["trending_attacks"]
        }
    
    def _assess_complexity(self, vuln: VulnerabilityResult) -> str:
        """Assess exploitation complexity"""
        if vuln.injection_type and "union" in vuln.injection_type.value.lower():
            return "Medium - Requires SQL knowledge"
        elif vuln.injection_type and "error" in vuln.injection_type.value.lower():
            return "Low - Easily exploitable"
        elif vuln.injection_type and "blind" in vuln.injection_type.value.lower():
            return "High - Requires advanced techniques"
        else:
            return "Medium - Standard exploitation"
    
    def generate_security_metrics(self, vulnerabilities: List[VulnerabilityResult]) -> SecurityMetrics:
        """Generate comprehensive security metrics"""
        if not vulnerabilities:
            return SecurityMetrics(0, 0, 0, 0, 0, 100.0, {}, {})
        
        # Analyze all vulnerabilities
        analyses = [self.analyze_vulnerability(vuln) for vuln in vulnerabilities]
        
        # Count by risk level
        risk_counts = Counter(analysis.risk_level for analysis in analyses)
        
        total = len(vulnerabilities)
        critical = risk_counts.get(VulnerabilityRisk.CRITICAL, 0)
        high = risk_counts.get(VulnerabilityRisk.HIGH, 0)
        medium = risk_counts.get(VulnerabilityRisk.MEDIUM, 0)
        low = risk_counts.get(VulnerabilityRisk.LOW, 0)
        
        # Calculate security score (0-100)
        security_score = max(0, 100 - (critical * 25 + high * 15 + medium * 10 + low * 5))
        
        # Compliance status
        compliance = {
            "OWASP_TOP_10": critical == 0 and high <= 1,
            "PCI_DSS": critical == 0 and high == 0,
            "GDPR_COMPLIANT": critical == 0 and high <= 2,
            "SOX_COMPLIANT": critical == 0 and high == 0 and medium <= 3
        }
        
        # Trending analysis
        trending = {
            "risk_trend": "increasing" if critical > 0 or high > 2 else "stable",
            "most_common_type": self._get_most_common_type(vulnerabilities),
            "average_risk_score": statistics.mean(a.risk_score for a in analyses)
        }
        
        return SecurityMetrics(
            total_vulnerabilities=total,
            critical_count=critical,
            high_count=high,
            medium_count=medium,
            low_count=low,
            security_score=security_score,
            compliance_status=compliance,
            trending_analysis=trending
        )
    
    def _get_most_common_type(self, vulnerabilities: List[VulnerabilityResult]) -> str:
        """Get most common vulnerability type"""
        types = [v.injection_type.value for v in vulnerabilities if v.injection_type]
        if types:
            return Counter(types).most_common(1)[0][0]
        return "Unknown"
